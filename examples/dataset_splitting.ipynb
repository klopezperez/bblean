{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3f205c3",
   "metadata": {},
   "source": [
    "# Dataset Splitting\n",
    "\n",
    "This notebook was modified from the original work of Pat Walters ([Some Thoughts on\n",
    "Splitting Chemical\n",
    "Datasets](https://practicalcheminformatics.blogspot.com/2024/11/some-thoughts-on-splitting-chemical.html))\n",
    "to include the [BitBIRCH](https://www.biorxiv.org/content/10.1101/2024.08.10.607459v1)\n",
    "clustering algorithm (from the work of the Miranda-Quintana Group), and a timing\n",
    "comparison with the Taylor-Butina method.\n",
    "\n",
    "It explores a few strategies for dataset splitting.  It also serves as a\n",
    "demonstration of some of the splitting capabilities in useful_rdkit_utils.\n",
    "\n",
    "Running this notebook **requires** installation of the `useful_rdkit_utils`, together with other utilities (`tqdm`, `statsmodels`, and `lightgbm`). Lets install these first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d2219-8f4d-4c8d-8169-92a8a1900567",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install useful_rdkit_utils tqdm statsmodels lightgbm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d3651f",
   "metadata": {},
   "source": [
    "Now we will import all necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d3043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdFingerprintGenerator, AllChem\n",
    "from rdkit.DataStructs import BulkTanimotoSimilarity, ExplicitBitVect\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "import useful_rdkit_utils as uru\n",
    "import bblean\n",
    "import bblean.fingerprints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5145477e",
   "metadata": {},
   "source": [
    "We will create a wrapper class for LGBM, required to work with `useful_rdkit_utils` (no need to worry too much about this, it is not essential to understanding the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e113177-52e1-446d-a20f-d74eb034d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LGBMMorganCountWrapper:\n",
    "    def __init__(self, y_col):\n",
    "        self.lgbm = LGBMRegressor(verbose=-1)\n",
    "        self.y_col = y_col\n",
    "        self.fp_name = \"fp\"\n",
    "        self.fg = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=1024)\n",
    "\n",
    "    def fit(self, train):\n",
    "        train[\"mol\"] = train.SMILES.apply(Chem.MolFromSmiles)\n",
    "        train[self.fp_name] = train.mol.apply(self.fg.GetCountFingerprintAsNumPy)\n",
    "        self.lgbm.fit(np.stack(train.fp), train[self.y_col])\n",
    "\n",
    "    def predict(self, test):\n",
    "        test[\"mol\"] = test.SMILES.apply(Chem.MolFromSmiles)\n",
    "        test[self.fp_name] = test.mol.apply(self.fg.GetCountFingerprintAsNumPy)\n",
    "        pred = self.lgbm.predict(np.stack(np.stack(test[self.fp_name])))\n",
    "        return pred\n",
    "\n",
    "    def validate(self, train, test):\n",
    "        self.fit(train)\n",
    "        pred = self.predict(test)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce72df",
   "metadata": {},
   "source": [
    "#### Read the Input Data\n",
    "\n",
    "Here are is a demo dataset. The **biogen_logS** dataset contains the log of aqueous\n",
    "solubility for a diverse datasets, taken from [a work on ML\n",
    "algorithm validation by Cheng Fang et\n",
    "al.](https://pubs.acs.org/doi/10.1021/acs.jcim.3c00160)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"biogen_logS.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667188df-fb58-4d86-b144-4e8161061e68",
   "metadata": {},
   "source": [
    "#### Cluster the Data\n",
    "\n",
    "In the next four cells we use functions from [useful_rdkit_utils](xxx) to define groups\n",
    "that will be used with **GroupKFoldShuffle** to generate training and test sets for\n",
    "cross validation. Molecules in the same cluster will be placed in either the training\n",
    "set or the test set, but not both.  The first method **get_random_split** simply puts\n",
    "every molecule into its own cluster, and can be used to generate a random split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a8671-3879-4024-81e9-cf73ae8c806e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"random_cluster\"] = uru.get_random_clusters(df.SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c51fde6-f5b8-439f-a41e-f91fed0fb063",
   "metadata": {},
   "source": [
    "The **get_bemis_murcko_clusters** method identifies the [Bemis-Murcko\n",
    "frameworks](https://pubs.acs.org/doi/10.1021/jm9602928), as defined by the\n",
    "[RDKit](https://www.rdkit.org/docs/source/rdkit.Chem.Scaffolds.MurckoScaffold.html), in\n",
    "each molecule and assigns each unique scaffold to a cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcf496-af39-4508-ba00-ea37f6e2b6e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"scaffold_cluster\"] = uru.get_bemis_murcko_clusters(df.SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b961a-357b-4131-9bca-782ce885a53e",
   "metadata": {},
   "source": [
    "The **get_butina_clusters** method starts by using the [Butina clustering\n",
    "method](https://pubs.acs.org/doi/pdf/10.1021/ci9803381) in the\n",
    "[RDKit](https://rdkit.org/docs/source/rdkit.ML.Cluster.Butina.html) to cluster\n",
    "molecules.  The default distance cutoff is 0.65, which corresponds to Tanimoto\n",
    "similairity of 0.35. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8508b6b-d522-4a4d-be57-63ec6d920fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"butina_cluster\"] = uru.get_butina_clusters(df.SMILES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8608132-77fd-4de7-997b-2f05610bfb14",
   "metadata": {},
   "source": [
    "The **get_umap_clusters** method follows a [paper](https://arxiv.org/abs/2406.00873) by\n",
    "Pedro Ballester's group.  In the paper, the Morgan fingerprints for the molecules are\n",
    "projected into a 2-dimensional space using the umap algorithm.  This 2-dimensional space\n",
    "is then clustered into 7 clusters using the AgglomerativeClustering method in\n",
    "scikit-learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d7d41-7deb-455c-899b-cdb64b6ba875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"umap_cluster\"] = uru.get_umap_clusters(df.SMILES, n_clusters=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fcb119-3f6a-47b3-bac7-a19893654645",
   "metadata": {},
   "source": [
    "After the operations above, the dataframe has four new columns corresponding to the\n",
    "clusters obtained using the methods in **useful_rdkit_utils**. We now are adding a\n",
    "function, **get_bitbirch_clusters**, to compute **BitBIRCH** clusters from SMILES given\n",
    "in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed14591-0f49-4b02-b035-d1a246504817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bitbirch_clusters(smiles_list):\n",
    "    mols = [Chem.MolFromSmiles(smiles) for smiles in smiles_list]\n",
    "    fps = np.array([Chem.RDKFingerprint(mol) for mol in mols])\n",
    "    bitbirch = bblean.BitBirch(branching_factor=50, threshold=0.65)\n",
    "    bitbirch.fit(fps)\n",
    "    cluster_list = bitbirch.get_cluster_mol_ids()\n",
    "\n",
    "    #     # Map each mol ID to its cluster ID\n",
    "    n_molecules = len(fps)\n",
    "    cluster_labels = [0] * n_molecules\n",
    "    for cluster_id, indices in enumerate(cluster_list):\n",
    "        for idx in indices:\n",
    "            cluster_labels[idx] = cluster_id\n",
    "    return cluster_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b113261-e6ce-406a-9752-94a9d79b4280",
   "metadata": {},
   "source": [
    "The following cell will add a column to the dataframe with a the corresponding\n",
    "**BitBIRCH** cluster IDs, as well as save the binary fingerprints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182ac56-25fc-4932-93ad-c6278be30222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"bitbirch_cluster\"] = get_bitbirch_clusters(df.SMILES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3881b13d-d9a0-4a5b-aec1-f1f4d4e3b0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7788a3-57f7-43d3-9551-5eb93dd6c1bd",
   "metadata": {},
   "source": [
    "#### Comparing Dataset Sizes\n",
    "\n",
    "Perform 5x5 cross-validation and examine the dataset sizes produced by the five\n",
    "splitting strategies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0fb045-9f58-4730-81fb-f234063db9ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size_df = pd.read_csv(\"biogen_logS.csv\")\n",
    "size_df[\"mol\"] = size_df.SMILES.apply(Chem.MolFromSmiles)\n",
    "fpgen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "size_df[\"fp\"] = size_df.mol.apply(fpgen.GetCountFingerprintAsNumPy)\n",
    "size_df[\"binary_fps\"] = size_df.mol.apply(Chem.RDKFingerprint)\n",
    "\n",
    "SPLIT_LIST = [\n",
    "    \"random_cluster\",\n",
    "    \"butina_cluster\",\n",
    "    \"umap_cluster\",\n",
    "    \"scaffold_cluster\",\n",
    "    \"bitbirch_cluster\",\n",
    "]\n",
    "split_fn_dict = {\n",
    "    \"random_cluster\": uru.get_random_clusters,\n",
    "    \"butina_cluster\": uru.get_butina_clusters,\n",
    "    \"umap_cluster\": uru.get_umap_clusters,\n",
    "    \"scaffold_cluster\": uru.get_bemis_murcko_clusters,\n",
    "    \"bitbirch_cluster\": get_bitbirch_clusters,\n",
    "}\n",
    "\n",
    "result_list = []\n",
    "for split in SPLIT_LIST:\n",
    "    for i in tqdm(range(0, 5), desc=split):\n",
    "        cluster_list = split_fn_dict[split](size_df.SMILES)\n",
    "        group_kfold_shuffle = uru.GroupKFoldShuffle(n_splits=5, shuffle=True)\n",
    "        if split == \"bitbirch_cluster\":\n",
    "            for train, test in group_kfold_shuffle.split(\n",
    "                np.stack(size_df.binary_fps), size_df.logS, cluster_list\n",
    "            ):\n",
    "                result_list.append([split, len(test)])\n",
    "        else:\n",
    "            for train, test in group_kfold_shuffle.split(\n",
    "                np.stack(size_df.fp), size_df.logS, cluster_list\n",
    "            ):\n",
    "                result_list.append([split, len(test)])\n",
    "result_df = pd.DataFrame(result_list, columns=[\"split\", \"num_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178fc9a-22ec-44ed-9792-124f22ab83fa",
   "metadata": {},
   "source": [
    "As expected, the test set sizes are the same when **random_cluster** is used.  With\n",
    "**butina_cluster**, **scaffold_cluster**, and **bitbirch_cluster** we see a bit more\n",
    "variability in test set sizes.  When we use **umap_cluster** there a large variability\n",
    "in the test size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c212e276-6a1b-4609-bc71-6e7c2d699da2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.boxplot(x=\"split\", y=\"num_test\", data=result_df)\n",
    "ax.set_xlabel(\"Dataset Splitting Strategy\")\n",
    "ax.set_ylabel(\"Test Set Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b1d280-dd43-49cd-bf8b-2ce7d805d486",
   "metadata": {},
   "source": [
    "The variability in test set size with **umap_cluster** can be attributed to the\n",
    "variation in cluster sizes.  Some of this may be due to the fact that we're only using 7\n",
    "clusters.  Let's examine the impact of the number of clusters from\n",
    "AgglomerativeClustering on the size of the test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18443c08-1684-4ee7-a340-bed6150b2a83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urc_result_list = []\n",
    "for num_clus in tqdm(range(5, 76, 5)):\n",
    "    for i in range(0, 5):\n",
    "        cluster_list = uru.get_umap_clusters(size_df.SMILES, n_clusters=num_clus)\n",
    "        group_kfold_shuffle = uru.GroupKFoldShuffle(n_splits=5, shuffle=True)\n",
    "        for train, test in group_kfold_shuffle.split(\n",
    "            np.stack(size_df.fp), size_df.logS, cluster_list\n",
    "        ):\n",
    "            urc_result_list.append([num_clus, len(test)])\n",
    "urc_result_df = pd.DataFrame(urc_result_list, columns=[\"num_clus\", \"num_test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b38642-2965-46f2-82eb-fcaff5e2adad",
   "metadata": {},
   "source": [
    "Looking at the plot below, the test set size seems to stabilize when we reach about 35 clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405a4ee0-ca3c-4db9-ae83-11116f92ed5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"num_clus\", y=\"num_test\", data=urc_result_df)\n",
    "ax.set_xlabel(\"Number of Clusters\")\n",
    "ax.set_ylabel(\"Number of Test Set Molecules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f09d87-9bbb-446a-9de7-1b5178b20e1e",
   "metadata": {},
   "source": [
    "#### Make t-SNE Plots to Compare the Data Splits \n",
    "\n",
    "We would like to generate a plot to visualize the training and test set distributions\n",
    "for our dataset using the different splitting methods.  To do this, we'll project the\n",
    "fingerprints into two dimensions using truncate stochastic neighbor embedding (tSNE).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b083867-a9fd-4aca-9855-c1ad82444480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_tsne_coords(smiles_list):\n",
    "    fp_gen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    mol_list = [Chem.MolFromSmiles(x) for x in smiles_list]\n",
    "    fp_list = [\n",
    "        fp_gen.GetFingerprintAsNumPy(x) for x in mol_list\n",
    "    ]  # Using binary fingerprints in this test\n",
    "    pca = PCA(n_components=50)\n",
    "    pcs = pca.fit_transform(fp_list)\n",
    "    tsne = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\")\n",
    "    res = tsne.fit_transform(pcs)\n",
    "    tsne_x = res[:, 0]\n",
    "    tsne_y = res[:, 1]\n",
    "    return tsne_x, tsne_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2493d93c-b1b1-4143-8f25-ca45a9d753c2",
   "metadata": {},
   "source": [
    "Use **GroupKFoldShuffle** to split the dataset using each of methods we defined above.\n",
    "Since this is simply a visual illustration, we'll only do one round of cross validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4795bf-0945-4620-b3f9-59705d0240c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_dict = {}\n",
    "for split in SPLIT_LIST:\n",
    "    kf = uru.GroupKFoldShuffle(n_splits=5, shuffle=True)\n",
    "    for train_idx, test_idx in kf.split(df, groups=df[split]):\n",
    "        split_dict[split] = [train_idx, test_idx]\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586252f5-6ab1-431b-9b8f-4e7b93c0c567",
   "metadata": {},
   "source": [
    "Any cross validation method that splits a dataset based on clusters, won't produce the\n",
    "same test set size every time.  Let's look at the training and test set sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca1319-839f-4a06-b9dd-d8c40020813e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for k, v in split_dict.items():\n",
    "    print(k, len(v[0]), len(v[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7604c87b-ff33-4836-b734-33c49521303a",
   "metadata": {},
   "source": [
    "Get tSNE 2D coordinates for the molecules and add them to the dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c942a-867f-40c8-bd26-ae4fcdf381f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tsne_x, tsne_y = get_tsne_coords(df.SMILES)\n",
    "\n",
    "df[\"tsne_x\"] = tsne_x\n",
    "df[\"tsne_y\"] = tsne_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c72d52-fad0-414e-93f9-610d54849c70",
   "metadata": {},
   "source": [
    "Create a new dataframe with the tSNE coordiantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549d06c9-d929-448b-bee3-4301a31c26cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_df = df[[\"tsne_x\", \"tsne_y\"]].copy()\n",
    "tmp_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2680574-79d1-4667-9c20-d3b265b94ee1",
   "metadata": {},
   "source": [
    "Add training and test set labels to **tmp_df** using the four splitting methods defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f004fb9-7f8d-4e51-87ce-2b0563b53dfe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in SPLIT_LIST:\n",
    "    tmp_df[split] = \"train\"\n",
    "    _, test_idx = split_dict[split]\n",
    "    for t in test_idx:\n",
    "        tmp_df.loc[t, split] = \"test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98796e1c-53f7-4379-9466-0748266352d8",
   "metadata": {},
   "source": [
    "Plot the chemical space of the dataset and show the training set in light blue and the\n",
    "test set in red. To be honest, I don't see a large difference between the plots. The\n",
    "only obvious difference is with **umap_cluster** where the test set is much more\n",
    "localized. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7114d572-d408-4d63-8332-6e795578c126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbfdeb5-00d3-474c-a0e0-9d0cc9e55362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "sns.set_context(\"talk\")\n",
    "figure, axes = plt.subplots(1, 5, figsize=(15, 5), sharey=True)\n",
    "for i, split in enumerate(SPLIT_LIST):\n",
    "    scatter_ax = sns.scatterplot(\n",
    "        x=\"tsne_x\",\n",
    "        y=\"tsne_y\",\n",
    "        data=tmp_df.query(f\"{split} == 'train'\"),\n",
    "        ax=axes[i],\n",
    "        color=\"lightblue\",\n",
    "        alpha=0.3,\n",
    "        legend=False,\n",
    "    )\n",
    "    sns.scatterplot(\n",
    "        x=\"tsne_x\",\n",
    "        y=\"tsne_y\",\n",
    "        data=tmp_df.query(f\"{split} == 'test'\"),\n",
    "        ax=axes[i],\n",
    "        color=\"red\",\n",
    "        alpha=0.5,\n",
    "        legend=False,\n",
    "    )\n",
    "    scatter_ax.set_title(split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303527f1-4baf-4189-bf5a-8dc4d2a99878",
   "metadata": {},
   "source": [
    "#### Calculate the Tanimoto Similarity Between the Training and Test Sets\n",
    "\n",
    "The t-SNE plots weren't very satisfying. Instead, let's try another approach.  We will\n",
    "make box plots comparing the similarity to the 5 nearest training set neighbors for each\n",
    "test set molecule.  First we'll write a function to do the similarity calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83605fec-28d3-4029-8a8a-847d95705c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test_tanimoto(train_smiles_list, test_smiles_list, top_n=5):\n",
    "    fp_gen = rdFingerprintGenerator.GetMorganGenerator()\n",
    "    train_mol_list = [Chem.MolFromSmiles(x) for x in train_smiles_list]\n",
    "    # Binary fingerprints\n",
    "    train_fp_list = [fp_gen.GetFingerprint(x) for x in train_mol_list]\n",
    "    test_mol_list = [Chem.MolFromSmiles(x) for x in test_smiles_list]\n",
    "    test_fp_list = [fp_gen.GetFingerprint(x) for x in test_mol_list]\n",
    "    result_list = []\n",
    "    for test_fp in test_fp_list:\n",
    "        sim_list = BulkTanimotoSimilarity(test_fp, train_fp_list)\n",
    "        sim_array = np.array(sim_list)\n",
    "        idx = np.argpartition(np.array(sim_array), -top_n)[-top_n:]\n",
    "        best_n_tanimoto = sim_array[idx]\n",
    "        result_list.append(best_n_tanimoto)\n",
    "    return np.array(result_list).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfdc14e-b8a8-4ddd-9828-c85e12d95a1e",
   "metadata": {},
   "source": [
    "Perform 5x5-fold cross validation calculating the Tanimoto similarity between test set\n",
    "molecules and training set molecules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664f594-4514-49f1-98fc-957c802f4dd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for split in SPLIT_LIST:\n",
    "    fold = 0\n",
    "    idx = 0\n",
    "    for i in tqdm(range(0, 5), desc=split):\n",
    "        kf = uru.GroupKFoldShuffle(n_splits=5, shuffle=True)\n",
    "        for train_idx, test_idx in kf.split(df, groups=df[split]):\n",
    "            train = df.iloc[train_idx]\n",
    "            test = df.iloc[test_idx]\n",
    "            sim_vals = train_test_tanimoto(train.SMILES, test.SMILES)\n",
    "            idx = np.arange(0, len(sim_vals)) + fold * len(sim_vals)\n",
    "            sim_df = pd.DataFrame(\n",
    "                {\"sim\": sim_vals, \"fold\": fold, \"split\": split, \"idx\": idx}\n",
    "            )\n",
    "            fold += 1\n",
    "            df_list.append(sim_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981239a-449e-4932-9fa5-0d1e1cd90258",
   "metadata": {},
   "source": [
    "Plot distributions of Tamimoto similarity for the 5 nearest neighbors for each test set\n",
    "molecule.  Only plot the first 10 cross-validation folds so the plot doesn't get overly\n",
    "crowded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6931b5eb-16b2-4c40-ad59-2469441496fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combo_df = pd.concat(df_list)\n",
    "sns.set(rc={\"figure.figsize\": (15, 10)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "ax = sns.boxplot(data=combo_df.query(\"fold < 10\"), x=\"fold\", y=\"sim\", hue=\"split\")\n",
    "ax.legend(loc=\"upper left\", bbox_to_anchor=(1.00, 0.75), ncol=1)\n",
    "ax.set_xlabel(\"Cross-validation Fold\")\n",
    "ax.set_ylabel(\"Tanimoto Similairty to 5 Nearest Neighbors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220adaf7-fa14-4266-9ea5-f756e0541131",
   "metadata": {},
   "source": [
    "Make boxplots of Tanimoto similarity of each test set molecule to its 5 nearest\n",
    "neighbors.  This is simply the plot above where all cross-validation fold are pooled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610714f2-f4d0-4f62-a999-f5c0c9119856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.figsize\": (10, 5)})\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(data=combo_df, x=\"split\", y=\"sim\", hue=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d227aae2-364f-4a61-9f91-3729b0351f15",
   "metadata": {},
   "source": [
    "As stated by Walters, there is a \"a strong correlation between model performance and the\n",
    "similarity of each test set molecule to its five nearest training set neighbors\".\n",
    "**random_cluster**, **bitbirch_cluster** and **scaffold_cluster** provide more neighbors\n",
    "compared to the other methods. \n",
    "\n",
    "Use the Tukey Honestly Significant Difference (HSD) test to determine whether the\n",
    "differences between Tanimoto similairty distributions are signficant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc10123-0a11-44ea-8e04-cecef8a86cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tukey_res = pairwise_tukeyhsd(combo_df.sim, combo_df.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414bcb70-b840-445d-b778-97565ff1c692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tukey_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d7b62c-6843-46a7-8ee5-734f4845e49b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "_ = tukey_res.plot_simultaneous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03f0212-29f2-41e9-8591-5eccdb10cbb7",
   "metadata": {},
   "source": [
    "#### Examine the Impact of Dataset Splitting on ML Model Performance \n",
    "\n",
    "We've seen how the different splitting methods affect the similairty between the\n",
    "training and test sets.  Now let's see how the same splits impact model performance.  To\n",
    "do this, we will use the **cross_validate** function in useful_rdkit_utils.  To use the\n",
    "function we pass the following arguments. \n",
    "\n",
    "* An input dataframe, which must contain a SMILES column\n",
    "* A list of tuples containing a model name and and instance of a wrapper class that runs\n",
    "  a model. The wrapper class must support an **evaluate** function which takes\n",
    "  dataframes containing training and test sets as input and returns a list of\n",
    "  predictions for the test set.\n",
    "* The name of the **y** variable in the dataframe\n",
    "* A list of tuples containing a name and a function to group the data.  These groups\n",
    "  will be passed to an instance of **GroupKFoldShuffle**\n",
    "* The number of outer cross-validation folds\n",
    "* The number of inner cross-validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f89109c-b57a-4d17-9ea7-1751bea5e547",
   "metadata": {},
   "source": [
    "While this may sound complicated, it's actually simple.  The code block below defines\n",
    "the model list, the group list, and the y column. We are comparing \n",
    "\n",
    "* one model - LightGBM\n",
    "* five splitting methods - butina, random, scaffold, bitbirch, and umap\n",
    "  \n",
    "The **y** column in the dataset is **logS**.  That's it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb7e21f-88da-49c7-8aa8-1131146f8e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_list = [(\"lgbm_morgan\", LGBMMorganCountWrapper)]\n",
    "group_list = [\n",
    "    (\"butina\", uru.get_butina_clusters),\n",
    "    (\"random\", uru.get_random_clusters),\n",
    "    (\"scaffold\", uru.get_bemis_murcko_clusters),\n",
    "    (\"umap\", uru.get_umap_clusters),\n",
    "    (\"bitbirch\", get_bitbirch_clusters),\n",
    "]\n",
    "y = \"logS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9f5a13-7204-4fcb-ae37-3fd9a1ffdbb8",
   "metadata": {},
   "source": [
    "With the definitions above, call **cross_validate**, which returns a dataframe with the\n",
    "training and test sets for each fold, as well as the predicted values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6c4610-7156-4dd5-b827-429489aa1d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_df = uru.cross_validate(df, model_list, y, group_list, 5, 5)\n",
    "outfile_name = \"biogen_logS_results.csv\"\n",
    "result_df.to_csv(outfile_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9180139-0e96-41a0-88f5-c8ecd217292b",
   "metadata": {},
   "source": [
    "Now, we'll calculate some statistics on the dataset.  To do this, we only need the data\n",
    "from the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe03f83-3da0-4b9e-894a-ea6a8e015074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = result_df.query(\"dset == 'test'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdcdc47-7884-44d3-ad15-69013ef28389",
   "metadata": {},
   "source": [
    "Collect the data from the cross-validation folds and calculate $R^2$ for each fold.\n",
    "This will give us a distribution of $R^2$ values for each splitting method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30017163-1afd-4c21-82b7-22dbaf3a3f64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_list = []\n",
    "for k, v in test_df.groupby([\"group\", \"fold\"]):\n",
    "    group, fold = k\n",
    "    r2 = r2_score(v.logS, v.lgbm_morgan)\n",
    "    out_list.append([group, fold, r2])\n",
    "out_df = pd.DataFrame(out_list, columns=[\"split\", \"fold\", \"r2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e46ff-4406-44a1-98ed-7a8fba5dfde9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b92c11-048f-4e40-85a5-35cfef0fe52d",
   "metadata": {},
   "source": [
    "Plot a boxplot showing the $R^2$ distributions for each splitting method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb0b085-d784-4713-b44b-ee3287dc5f0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "ax = sns.boxplot(x=\"split\", y=\"r2\", hue=\"split\", data=out_df)\n",
    "ax.set_ylabel(\"$R^2$\")\n",
    "ax.set_xlabel(\"Split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef0e6e-dbba-4406-acaf-192085defafc",
   "metadata": {},
   "source": [
    "From the plot above, it's clear that the **umap** splits are the most challenging for\n",
    "the model.  The $R^2$ distributions for the **bitbirch** split and the **random** split\n",
    "appear similar, generating models with higher $R^2$ values. We can use the Tukey HSD\n",
    "test to determine whether statistically significant differences exist between the\n",
    "splitting methods.  The table **tukey_res** table below shows the following. \n",
    "\n",
    "* **group1** - the first split being compared\n",
    "* **group2** - the second split being compared\n",
    "* **meandiff** - the mean difference between the two splitting methods\n",
    "* **p-adj** - the p-value for the difference between distributions, corrected for multiple comparisons\n",
    "* **lower** - the lower bound of the confidence interval\n",
    "* **upper** - the upper bound of thhe confidence interval\n",
    "* **reject** - can we reject the null hypothesis that the means of the distributions are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711e87f-9de3-485b-9b6d-cd74f12376cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tukey_res = pairwise_tukeyhsd(out_df.r2, out_df.split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f6cd8-15a0-4feb-844f-0483f2e0308f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tukey_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b600a-1180-43ea-85e9-d324f010cc74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "_ = tukey_res.plot_simultaneous(comparison_name=\"umap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca423d-4afd-41d7-b9d0-631875fdf79b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Compare BitBIRCH and Butina Timing\n",
    "\n",
    "We would like to see how the speed of **BitBIRCH** compares to that of **Butina**. We\n",
    "want to only compare the clustering method itself, without having to account for the\n",
    "fingerprint computation. Now that we have stored fingerprints in size_df, we will do a\n",
    "quick comparison of the two methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6256463-8d53-4633-9201-7c87df5b8828",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def numpy_to_explicit_bitvect(fp):\n",
    "    bitvect = ExplicitBitVect(len(fp))\n",
    "    for idx, val in enumerate(fp):\n",
    "        if val:\n",
    "            bitvect.SetBit(idx)\n",
    "    return bitvect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953432a-23c3-4f4a-ae39-a46c847cc0ad",
   "metadata": {},
   "source": [
    "#### Comparison with biogen data (2173 total molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcbdbdb-7877-4050-a087-c1bb87992973",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.array(size_df.binary_fps.values.tolist())\n",
    "rdkit_fp_list = [numpy_to_explicit_bitvect(fp) for fp in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb054db6-265d-45e6-a4fc-a3e25a93210f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "bitbirch = bblean.BitBirch(branching_factor=50, threshold=0.65)\n",
    "bitbirch.fit(data)\n",
    "bitbirch_time = time.time() - s_time\n",
    "print(\"Time for BitBIRCH Clustering (s):\", bitbirch_time)\n",
    "\n",
    "dists = []\n",
    "nfps = len(rdkit_fp_list)\n",
    "s_time = time.time()\n",
    "for i in range(1, nfps):\n",
    "    sims = BulkTanimotoSimilarity(rdkit_fp_list[i], rdkit_fp_list[:i])\n",
    "    dists.extend([1 - x for x in sims])\n",
    "cluster_res = Butina.ClusterData(dists, nfps, 0.65, isDistData=True)\n",
    "butina_time = time.time() - s_time\n",
    "print(\"Time for Butina Clustering (s):\", butina_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab70866-4571-48fb-8590-2f000d741afd",
   "metadata": {},
   "source": [
    "We see on the biogen dataset, of 2173 structures, **BitBIRCH** performs significantly faster\n",
    "than **Butina** (around 2x). Let's see how the two methods compare\n",
    "on a larger dataset. \n",
    "\n",
    "#### Comparison with sample of the Chembl library (20,000 total molecules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd70451-a5d8-47dd-a8ad-d34b9c3cdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_smis = bblean.load_smiles(\"./chembl-33-natural-products-subset.smi\")[:20_000]\n",
    "fps = bblean.fingerprints\n",
    "\n",
    "chembl_rdkit_fp_list = [numpy_to_explicit_bitvect(fp) for fp in chembl_fps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332da7b4-a316-4464-8056-b6ac38248df9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_time = time.time()\n",
    "bitbirch = bblean.BitBirch(branching_factor=50, threshold=0.65)\n",
    "bitbirch.fit(chembl_fps, input_is_packed=False)\n",
    "bitbirch_time = time.time() - s_time\n",
    "print(\"Time for BitBIRCH Clustering (s):\", bitbirch_time)\n",
    "\n",
    "\n",
    "dists = []\n",
    "nfps = len(chembl_rdkit_fp_list)\n",
    "s_time = time.time()\n",
    "for i in range(1, nfps):\n",
    "    sims = BulkTanimotoSimilarity(chembl_rdkit_fp_list[i], chembl_rdkit_fp_list[:i])\n",
    "    dists.extend([1 - x for x in sims])\n",
    "cluster_res = Butina.ClusterData(dists, nfps, 0.65, isDistData=True)\n",
    "butina_time = time.time() - s_time\n",
    "print(\"Time for Butina Clustering (s):\", butina_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430305a4-486e-4428-9b25-c4bffbc176ec",
   "metadata": {},
   "source": [
    "We see BitBIRCH vastly outperforms Butina in regards to speed on a dataset of 20k\n",
    "structures. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
